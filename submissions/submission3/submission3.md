Submission 3 - Optimized Single Random Forest By Feature Selection
========================================================


```r
load("rf1.RData")
```


```r
train <- read.csv("../data/processed/processed_train.csv")
test <- read.csv("../data/original/test.csv")
```



```r
require(randomForest)
```

```
## Loading required package: randomForest
## randomForest 4.6-7
## Type rfNews() to see new features/changes/bug fixes.
```

```r
require(plyr)
```

```
## Loading required package: plyr
```

```r

rf$importance
```

```
##                                     b         s MeanDecreaseAccuracy
## DER_mass_MMC                0.0694906 0.1379587            0.0929499
## DER_mass_transverse_met_lep 0.0497179 0.0488061            0.0494058
## DER_mass_vis                0.0493432 0.0528785            0.0505553
## DER_pt_h                    0.0217379 0.0431074            0.0290606
## DER_deltaeta_jet_jet        0.0063268 0.0306668            0.0146673
## DER_mass_jet_jet            0.0086810 0.0258875            0.0145771
## DER_prodeta_jet_jet         0.0072948 0.0044366            0.0063138
## DER_deltar_tau_lep          0.0343305 0.0448628            0.0379402
## DER_pt_tot                  0.0116108 0.0080096            0.0103769
## DER_sum_pt                  0.0354522 0.0391069            0.0367061
## DER_pt_ratio_lep_tau        0.0258481 0.0264103            0.0260422
## DER_met_phi_centrality      0.0290101 0.0287805            0.0289309
## DER_lep_eta_centrality      0.0017128 0.0402441            0.0149157
## PRI_tau_pt                  0.0312563 0.0499112            0.0376483
## PRI_tau_eta                 0.0016172 0.0035424            0.0022770
## PRI_tau_phi                 0.0002129 0.0006165            0.0003511
## PRI_lep_pt                  0.0156537 0.0113583            0.0141824
## PRI_lep_eta                 0.0017264 0.0048161            0.0027852
## PRI_lep_phi                 0.0004734 0.0008659            0.0006079
## PRI_met                     0.0173918 0.0270294            0.0206946
## PRI_met_phi                 0.0005440 0.0007597            0.0006180
## PRI_met_sumet               0.0164029 0.0103920            0.0143438
## PRI_jet_num                 0.0051426 0.0032512            0.0044945
## PRI_jet_leading_pt          0.0209174 0.0226732            0.0215202
## PRI_jet_leading_eta         0.0158220 0.0061857            0.0125195
## PRI_jet_leading_phi         0.0086197 0.0123659            0.0099041
## PRI_jet_subleading_pt       0.0044766 0.0096404            0.0062455
## PRI_jet_subleading_eta      0.0047714 0.0050334            0.0048606
## PRI_jet_subleading_phi      0.0052324 0.0049865            0.0051475
## PRI_jet_all_pt              0.0226330 0.0270445            0.0241449
##                             MeanDecreaseGini
## DER_mass_MMC                         18088.2
## DER_mass_transverse_met_lep          11553.1
## DER_mass_vis                          8723.1
## DER_pt_h                              3649.0
## DER_deltaeta_jet_jet                  2338.1
## DER_mass_jet_jet                      1779.8
## DER_prodeta_jet_jet                    956.1
## DER_deltar_tau_lep                    5091.3
## DER_pt_tot                            3299.3
## DER_sum_pt                            3286.0
## DER_pt_ratio_lep_tau                  5058.8
## DER_met_phi_centrality                5712.0
## DER_lep_eta_centrality                1828.8
## PRI_tau_pt                            6472.1
## PRI_tau_eta                           2838.9
## PRI_tau_phi                           2630.5
## PRI_lep_pt                            3077.8
## PRI_lep_eta                           2969.4
## PRI_lep_phi                           2625.0
## PRI_met                               4376.8
## PRI_met_phi                           2622.1
## PRI_met_sumet                         2972.6
## PRI_jet_num                            495.6
## PRI_jet_leading_pt                    1807.2
## PRI_jet_leading_eta                   2309.4
## PRI_jet_leading_phi                   1685.5
## PRI_jet_subleading_pt                  677.8
## PRI_jet_subleading_eta                 672.6
## PRI_jet_subleading_phi                 645.3
## PRI_jet_all_pt                        1870.1
```

```r

# Mean Decrease Gini
g <- importance(rf, type = 2, scale = F)
gini <- data.frame(variables = rownames(g), MeanDecreaseGini = g[1:nrow(g)], 
    stringsAsFactors = F)
arrange(gini, desc(MeanDecreaseGini))
```

```
##                      variables MeanDecreaseGini
## 1                 DER_mass_MMC          18088.2
## 2  DER_mass_transverse_met_lep          11553.1
## 3                 DER_mass_vis           8723.1
## 4                   PRI_tau_pt           6472.1
## 5       DER_met_phi_centrality           5712.0
## 6           DER_deltar_tau_lep           5091.3
## 7         DER_pt_ratio_lep_tau           5058.8
## 8                      PRI_met           4376.8
## 9                     DER_pt_h           3649.0
## 10                  DER_pt_tot           3299.3
## 11                  DER_sum_pt           3286.0
## 12                  PRI_lep_pt           3077.8
## 13               PRI_met_sumet           2972.6
## 14                 PRI_lep_eta           2969.4
## 15                 PRI_tau_eta           2838.9
## 16                 PRI_tau_phi           2630.5
## 17                 PRI_lep_phi           2625.0
## 18                 PRI_met_phi           2622.1
## 19        DER_deltaeta_jet_jet           2338.1
## 20         PRI_jet_leading_eta           2309.4
## 21              PRI_jet_all_pt           1870.1
## 22      DER_lep_eta_centrality           1828.8
## 23          PRI_jet_leading_pt           1807.2
## 24            DER_mass_jet_jet           1779.8
## 25         PRI_jet_leading_phi           1685.5
## 26         DER_prodeta_jet_jet            956.1
## 27       PRI_jet_subleading_pt            677.8
## 28      PRI_jet_subleading_eta            672.6
## 29      PRI_jet_subleading_phi            645.3
## 30                 PRI_jet_num            495.6
```

```r

# Mean Decrease Accuracy
a <- importance(rf, type = 1, scale = F)
accuracy <- data.frame(variables = rownames(a), MeanDecreaseAccuracy = a[1:nrow(a)], 
    stringsAsFactors = F)
arrange(accuracy, desc(MeanDecreaseAccuracy))
```

```
##                      variables MeanDecreaseAccuracy
## 1                 DER_mass_MMC            0.0929499
## 2                 DER_mass_vis            0.0505553
## 3  DER_mass_transverse_met_lep            0.0494058
## 4           DER_deltar_tau_lep            0.0379402
## 5                   PRI_tau_pt            0.0376483
## 6                   DER_sum_pt            0.0367061
## 7                     DER_pt_h            0.0290606
## 8       DER_met_phi_centrality            0.0289309
## 9         DER_pt_ratio_lep_tau            0.0260422
## 10              PRI_jet_all_pt            0.0241449
## 11          PRI_jet_leading_pt            0.0215202
## 12                     PRI_met            0.0206946
## 13      DER_lep_eta_centrality            0.0149157
## 14        DER_deltaeta_jet_jet            0.0146673
## 15            DER_mass_jet_jet            0.0145771
## 16               PRI_met_sumet            0.0143438
## 17                  PRI_lep_pt            0.0141824
## 18         PRI_jet_leading_eta            0.0125195
## 19                  DER_pt_tot            0.0103769
## 20         PRI_jet_leading_phi            0.0099041
## 21         DER_prodeta_jet_jet            0.0063138
## 22       PRI_jet_subleading_pt            0.0062455
## 23      PRI_jet_subleading_phi            0.0051475
## 24      PRI_jet_subleading_eta            0.0048606
## 25                 PRI_jet_num            0.0044945
## 26                 PRI_lep_eta            0.0027852
## 27                 PRI_tau_eta            0.0022770
## 28                 PRI_met_phi            0.0006180
## 29                 PRI_lep_phi            0.0006079
## 30                 PRI_tau_phi            0.0003511
```

```r

include <- unique(c(gini$variables[1:5]), accuracy$variables[1:5])
```

Run a new random forest including only the top 5 variables based on Gini and Accuracy

```r
rf2 <- randomForest(x = train[, include], y = train$Label, importance = T)
rf2
```

```
## 
## Call:
##  randomForest(x = train[, include], y = train$Label, importance = T) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 18.58%
## Confusion matrix:
##        b     s class.error
## b 145228 19105      0.1163
## s  27356 58311      0.3193
```


```r
rf2$err.rate
```

```
##           OOB      b      s
##   [1,] 0.2522 0.1914 0.3690
##   [2,] 0.2533 0.1924 0.3699
##   [3,] 0.2505 0.1902 0.3661
##   [4,] 0.2474 0.1865 0.3642
##   [5,] 0.2429 0.1818 0.3602
##   [6,] 0.2395 0.1775 0.3586
##   [7,] 0.2350 0.1729 0.3543
##   [8,] 0.2307 0.1675 0.3520
##   [9,] 0.2269 0.1629 0.3495
##  [10,] 0.2232 0.1592 0.3460
##  [11,] 0.2211 0.1564 0.3452
##  [12,] 0.2176 0.1528 0.3420
##  [13,] 0.2156 0.1510 0.3398
##  [14,] 0.2132 0.1480 0.3382
##  [15,] 0.2114 0.1460 0.3368
##  [16,] 0.2096 0.1441 0.3354
##  [17,] 0.2084 0.1423 0.3354
##  [18,] 0.2071 0.1411 0.3338
##  [19,] 0.2054 0.1390 0.3328
##  [20,] 0.2048 0.1388 0.3313
##  [21,] 0.2044 0.1382 0.3315
##  [22,] 0.2026 0.1363 0.3297
##  [23,] 0.2020 0.1358 0.3291
##  [24,] 0.2009 0.1344 0.3285
##  [25,] 0.2008 0.1340 0.3289
##  [26,] 0.1999 0.1330 0.3282
##  [27,] 0.1996 0.1324 0.3286
##  [28,] 0.1988 0.1317 0.3276
##  [29,] 0.1986 0.1313 0.3278
##  [30,] 0.1980 0.1305 0.3274
##  [31,] 0.1976 0.1300 0.3272
##  [32,] 0.1975 0.1301 0.3268
##  [33,] 0.1969 0.1293 0.3266
##  [34,] 0.1967 0.1291 0.3263
##  [35,] 0.1960 0.1288 0.3250
##  [36,] 0.1961 0.1286 0.3256
##  [37,] 0.1956 0.1282 0.3248
##  [38,] 0.1955 0.1280 0.3249
##  [39,] 0.1949 0.1274 0.3242
##  [40,] 0.1947 0.1274 0.3238
##  [41,] 0.1947 0.1271 0.3245
##  [42,] 0.1944 0.1268 0.3242
##  [43,] 0.1941 0.1263 0.3241
##  [44,] 0.1938 0.1261 0.3236
##  [45,] 0.1936 0.1260 0.3232
##  [46,] 0.1937 0.1259 0.3240
##  [47,] 0.1935 0.1256 0.3238
##  [48,] 0.1932 0.1254 0.3232
##  [49,] 0.1930 0.1251 0.3234
##  [50,] 0.1925 0.1248 0.3224
##  [51,] 0.1928 0.1248 0.3233
##  [52,] 0.1927 0.1248 0.3229
##  [53,] 0.1926 0.1247 0.3230
##  [54,] 0.1925 0.1246 0.3226
##  [55,] 0.1920 0.1239 0.3227
##  [56,] 0.1920 0.1238 0.3226
##  [57,] 0.1919 0.1238 0.3224
##  [58,] 0.1920 0.1240 0.3224
##  [59,] 0.1916 0.1232 0.3228
##  [60,] 0.1918 0.1233 0.3231
##  [61,] 0.1915 0.1230 0.3229
##  [62,] 0.1914 0.1229 0.3228
##  [63,] 0.1912 0.1228 0.3223
##  [64,] 0.1911 0.1228 0.3220
##  [65,] 0.1909 0.1224 0.3223
##  [66,] 0.1909 0.1225 0.3221
##  [67,] 0.1907 0.1223 0.3219
##  [68,] 0.1906 0.1223 0.3217
##  [69,] 0.1904 0.1222 0.3214
##  [70,] 0.1905 0.1222 0.3216
##  [71,] 0.1901 0.1219 0.3209
##  [72,] 0.1902 0.1217 0.3215
##  [73,] 0.1903 0.1218 0.3218
##  [74,] 0.1903 0.1218 0.3217
##  [75,] 0.1903 0.1218 0.3218
##  [76,] 0.1905 0.1219 0.3221
##  [77,] 0.1902 0.1216 0.3219
##  [78,] 0.1900 0.1214 0.3217
##  [79,] 0.1898 0.1212 0.3214
##  [80,] 0.1898 0.1213 0.3214
##  [81,] 0.1897 0.1212 0.3210
##  [82,] 0.1898 0.1210 0.3216
##  [83,] 0.1896 0.1210 0.3210
##  [84,] 0.1895 0.1207 0.3214
##  [85,] 0.1897 0.1208 0.3218
##  [86,] 0.1897 0.1209 0.3217
##  [87,] 0.1895 0.1208 0.3213
##  [88,] 0.1893 0.1205 0.3214
##  [89,] 0.1892 0.1203 0.3213
##  [90,] 0.1893 0.1204 0.3214
##  [91,] 0.1890 0.1201 0.3214
##  [92,] 0.1891 0.1203 0.3211
##  [93,] 0.1891 0.1201 0.3215
##  [94,] 0.1890 0.1200 0.3215
##  [95,] 0.1892 0.1203 0.3212
##  [96,] 0.1889 0.1200 0.3210
##  [97,] 0.1889 0.1201 0.3210
##  [98,] 0.1891 0.1201 0.3215
##  [99,] 0.1889 0.1199 0.3213
## [100,] 0.1888 0.1198 0.3210
## [101,] 0.1889 0.1200 0.3211
## [102,] 0.1889 0.1200 0.3212
## [103,] 0.1888 0.1199 0.3208
## [104,] 0.1885 0.1196 0.3208
## [105,] 0.1886 0.1195 0.3211
## [106,] 0.1886 0.1195 0.3210
## [107,] 0.1885 0.1195 0.3210
## [108,] 0.1886 0.1196 0.3210
## [109,] 0.1887 0.1197 0.3210
## [110,] 0.1887 0.1197 0.3210
## [111,] 0.1885 0.1196 0.3208
## [112,] 0.1885 0.1194 0.3210
## [113,] 0.1883 0.1194 0.3206
## [114,] 0.1883 0.1193 0.3207
## [115,] 0.1884 0.1193 0.3210
## [116,] 0.1886 0.1195 0.3210
## [117,] 0.1883 0.1194 0.3205
## [118,] 0.1882 0.1193 0.3204
## [119,] 0.1880 0.1191 0.3202
## [120,] 0.1881 0.1192 0.3204
## [121,] 0.1880 0.1189 0.3206
## [122,] 0.1881 0.1192 0.3204
## [123,] 0.1883 0.1193 0.3207
## [124,] 0.1881 0.1191 0.3206
## [125,] 0.1882 0.1191 0.3207
## [126,] 0.1881 0.1189 0.3207
## [127,] 0.1881 0.1189 0.3208
## [128,] 0.1882 0.1191 0.3208
## [129,] 0.1882 0.1190 0.3208
## [130,] 0.1882 0.1189 0.3210
## [131,] 0.1881 0.1189 0.3209
## [132,] 0.1880 0.1188 0.3208
## [133,] 0.1879 0.1186 0.3206
## [134,] 0.1879 0.1186 0.3208
## [135,] 0.1877 0.1186 0.3202
## [136,] 0.1880 0.1186 0.3209
## [137,] 0.1878 0.1186 0.3206
## [138,] 0.1880 0.1188 0.3206
## [139,] 0.1878 0.1186 0.3207
## [140,] 0.1878 0.1185 0.3208
## [141,] 0.1881 0.1187 0.3213
## [142,] 0.1880 0.1186 0.3210
## [143,] 0.1878 0.1187 0.3205
## [144,] 0.1878 0.1185 0.3207
## [145,] 0.1878 0.1186 0.3205
## [146,] 0.1879 0.1185 0.3208
## [147,] 0.1876 0.1184 0.3204
## [148,] 0.1877 0.1186 0.3203
## [149,] 0.1878 0.1187 0.3203
## [150,] 0.1878 0.1188 0.3202
## [151,] 0.1878 0.1186 0.3204
## [152,] 0.1877 0.1186 0.3203
## [153,] 0.1876 0.1185 0.3201
## [154,] 0.1876 0.1184 0.3202
## [155,] 0.1876 0.1184 0.3202
## [156,] 0.1874 0.1184 0.3199
## [157,] 0.1874 0.1185 0.3197
## [158,] 0.1876 0.1186 0.3200
## [159,] 0.1874 0.1184 0.3197
## [160,] 0.1874 0.1185 0.3198
## [161,] 0.1875 0.1184 0.3202
## [162,] 0.1876 0.1186 0.3201
## [163,] 0.1877 0.1186 0.3204
## [164,] 0.1874 0.1185 0.3197
## [165,] 0.1875 0.1183 0.3202
## [166,] 0.1875 0.1184 0.3201
## [167,] 0.1876 0.1185 0.3202
## [168,] 0.1875 0.1183 0.3202
## [169,] 0.1874 0.1183 0.3200
## [170,] 0.1876 0.1184 0.3202
## [171,] 0.1873 0.1183 0.3199
## [172,] 0.1875 0.1184 0.3199
## [173,] 0.1874 0.1183 0.3200
## [174,] 0.1875 0.1183 0.3201
## [175,] 0.1874 0.1183 0.3200
## [176,] 0.1875 0.1183 0.3202
## [177,] 0.1873 0.1183 0.3198
## [178,] 0.1874 0.1184 0.3199
## [179,] 0.1874 0.1183 0.3199
## [180,] 0.1874 0.1182 0.3200
## [181,] 0.1872 0.1182 0.3197
## [182,] 0.1873 0.1182 0.3199
## [183,] 0.1873 0.1183 0.3197
## [184,] 0.1873 0.1182 0.3199
## [185,] 0.1873 0.1181 0.3200
## [186,] 0.1873 0.1182 0.3198
## [187,] 0.1873 0.1182 0.3198
## [188,] 0.1873 0.1183 0.3196
## [189,] 0.1873 0.1182 0.3198
## [190,] 0.1872 0.1181 0.3197
## [191,] 0.1873 0.1181 0.3200
## [192,] 0.1872 0.1181 0.3198
## [193,] 0.1873 0.1181 0.3199
## [194,] 0.1872 0.1181 0.3199
## [195,] 0.1872 0.1180 0.3200
## [196,] 0.1873 0.1181 0.3200
## [197,] 0.1873 0.1181 0.3201
## [198,] 0.1872 0.1180 0.3200
## [199,] 0.1872 0.1180 0.3200
## [200,] 0.1871 0.1178 0.3200
## [201,] 0.1872 0.1179 0.3200
## [202,] 0.1871 0.1179 0.3199
## [203,] 0.1871 0.1179 0.3199
## [204,] 0.1871 0.1179 0.3199
## [205,] 0.1872 0.1179 0.3200
## [206,] 0.1871 0.1180 0.3199
## [207,] 0.1871 0.1179 0.3200
## [208,] 0.1872 0.1179 0.3201
## [209,] 0.1871 0.1179 0.3199
## [210,] 0.1872 0.1179 0.3202
## [211,] 0.1873 0.1179 0.3204
## [212,] 0.1874 0.1180 0.3204
## [213,] 0.1873 0.1178 0.3206
## [214,] 0.1872 0.1178 0.3204
## [215,] 0.1872 0.1178 0.3203
## [216,] 0.1871 0.1177 0.3204
## [217,] 0.1873 0.1178 0.3205
## [218,] 0.1872 0.1179 0.3203
## [219,] 0.1871 0.1178 0.3200
## [220,] 0.1872 0.1179 0.3202
## [221,] 0.1873 0.1179 0.3204
## [222,] 0.1873 0.1178 0.3205
## [223,] 0.1872 0.1177 0.3205
## [224,] 0.1872 0.1178 0.3203
## [225,] 0.1871 0.1177 0.3204
## [226,] 0.1872 0.1178 0.3204
## [227,] 0.1873 0.1178 0.3205
## [228,] 0.1872 0.1178 0.3204
## [229,] 0.1873 0.1178 0.3204
## [230,] 0.1873 0.1179 0.3205
## [231,] 0.1872 0.1179 0.3202
## [232,] 0.1873 0.1179 0.3203
## [233,] 0.1873 0.1179 0.3205
## [234,] 0.1872 0.1178 0.3203
## [235,] 0.1871 0.1178 0.3200
## [236,] 0.1872 0.1178 0.3204
## [237,] 0.1872 0.1178 0.3203
## [238,] 0.1872 0.1178 0.3203
## [239,] 0.1871 0.1176 0.3204
## [240,] 0.1871 0.1177 0.3203
## [241,] 0.1870 0.1176 0.3200
## [242,] 0.1870 0.1176 0.3202
## [243,] 0.1870 0.1176 0.3200
## [244,] 0.1870 0.1178 0.3199
## [245,] 0.1871 0.1176 0.3203
## [246,] 0.1871 0.1176 0.3203
## [247,] 0.1870 0.1177 0.3200
## [248,] 0.1871 0.1176 0.3204
## [249,] 0.1869 0.1175 0.3199
## [250,] 0.1869 0.1176 0.3199
## [251,] 0.1869 0.1176 0.3198
## [252,] 0.1870 0.1177 0.3200
## [253,] 0.1870 0.1177 0.3200
## [254,] 0.1870 0.1177 0.3200
## [255,] 0.1871 0.1177 0.3202
## [256,] 0.1871 0.1178 0.3200
## [257,] 0.1872 0.1179 0.3201
## [258,] 0.1872 0.1178 0.3202
## [259,] 0.1870 0.1179 0.3198
## [260,] 0.1870 0.1178 0.3199
## [261,] 0.1871 0.1179 0.3199
## [262,] 0.1871 0.1178 0.3200
## [263,] 0.1872 0.1179 0.3200
## [264,] 0.1871 0.1178 0.3199
## [265,] 0.1872 0.1179 0.3202
## [266,] 0.1869 0.1176 0.3199
## [267,] 0.1870 0.1177 0.3199
## [268,] 0.1869 0.1176 0.3198
## [269,] 0.1868 0.1175 0.3197
## [270,] 0.1868 0.1176 0.3197
## [271,] 0.1869 0.1176 0.3199
## [272,] 0.1869 0.1176 0.3198
## [273,] 0.1868 0.1174 0.3199
## [274,] 0.1867 0.1174 0.3196
## [275,] 0.1869 0.1176 0.3199
## [276,] 0.1867 0.1174 0.3196
## [277,] 0.1868 0.1174 0.3197
## [278,] 0.1867 0.1175 0.3194
## [279,] 0.1867 0.1175 0.3196
## [280,] 0.1867 0.1174 0.3197
## [281,] 0.1867 0.1174 0.3198
## [282,] 0.1867 0.1174 0.3196
## [283,] 0.1867 0.1173 0.3199
## [284,] 0.1868 0.1173 0.3202
## [285,] 0.1868 0.1174 0.3200
## [286,] 0.1869 0.1175 0.3201
## [287,] 0.1868 0.1173 0.3201
## [288,] 0.1867 0.1172 0.3200
## [289,] 0.1868 0.1172 0.3203
## [290,] 0.1868 0.1173 0.3202
## [291,] 0.1868 0.1173 0.3202
## [292,] 0.1868 0.1173 0.3201
## [293,] 0.1867 0.1172 0.3201
## [294,] 0.1867 0.1172 0.3200
## [295,] 0.1864 0.1170 0.3196
## [296,] 0.1866 0.1172 0.3198
## [297,] 0.1867 0.1172 0.3199
## [298,] 0.1865 0.1171 0.3198
## [299,] 0.1866 0.1172 0.3196
## [300,] 0.1865 0.1171 0.3195
## [301,] 0.1865 0.1171 0.3196
## [302,] 0.1864 0.1170 0.3195
## [303,] 0.1866 0.1172 0.3199
## [304,] 0.1864 0.1170 0.3196
## [305,] 0.1864 0.1170 0.3196
## [306,] 0.1864 0.1171 0.3193
## [307,] 0.1865 0.1171 0.3196
## [308,] 0.1866 0.1172 0.3197
## [309,] 0.1865 0.1171 0.3196
## [310,] 0.1864 0.1170 0.3196
## [311,] 0.1864 0.1170 0.3195
## [312,] 0.1864 0.1170 0.3196
## [313,] 0.1864 0.1170 0.3195
## [314,] 0.1865 0.1170 0.3197
## [315,] 0.1865 0.1170 0.3198
## [316,] 0.1865 0.1170 0.3197
## [317,] 0.1864 0.1170 0.3196
## [318,] 0.1865 0.1171 0.3195
## [319,] 0.1865 0.1172 0.3194
## [320,] 0.1865 0.1171 0.3195
## [321,] 0.1865 0.1171 0.3196
## [322,] 0.1864 0.1170 0.3196
## [323,] 0.1864 0.1170 0.3196
## [324,] 0.1864 0.1170 0.3196
## [325,] 0.1865 0.1171 0.3196
## [326,] 0.1863 0.1170 0.3195
## [327,] 0.1864 0.1169 0.3196
## [328,] 0.1864 0.1170 0.3196
## [329,] 0.1864 0.1170 0.3196
## [330,] 0.1862 0.1169 0.3193
## [331,] 0.1864 0.1169 0.3197
## [332,] 0.1863 0.1169 0.3196
## [333,] 0.1863 0.1169 0.3195
## [334,] 0.1863 0.1169 0.3196
## [335,] 0.1865 0.1171 0.3196
## [336,] 0.1865 0.1171 0.3195
## [337,] 0.1864 0.1170 0.3196
## [338,] 0.1864 0.1170 0.3194
## [339,] 0.1864 0.1170 0.3195
## [340,] 0.1864 0.1170 0.3195
## [341,] 0.1866 0.1171 0.3199
## [342,] 0.1865 0.1172 0.3196
## [343,] 0.1865 0.1171 0.3195
## [344,] 0.1865 0.1172 0.3195
## [345,] 0.1864 0.1171 0.3194
## [346,] 0.1865 0.1172 0.3194
## [347,] 0.1864 0.1170 0.3196
## [348,] 0.1865 0.1171 0.3196
## [349,] 0.1864 0.1170 0.3197
## [350,] 0.1865 0.1170 0.3198
## [351,] 0.1865 0.1170 0.3197
## [352,] 0.1864 0.1170 0.3196
## [353,] 0.1863 0.1169 0.3194
## [354,] 0.1864 0.1169 0.3197
## [355,] 0.1865 0.1170 0.3199
## [356,] 0.1864 0.1169 0.3199
## [357,] 0.1865 0.1169 0.3198
## [358,] 0.1864 0.1169 0.3197
## [359,] 0.1865 0.1170 0.3199
## [360,] 0.1865 0.1169 0.3199
## [361,] 0.1864 0.1169 0.3198
## [362,] 0.1864 0.1168 0.3200
## [363,] 0.1864 0.1169 0.3196
## [364,] 0.1863 0.1168 0.3196
## [365,] 0.1863 0.1168 0.3197
## [366,] 0.1863 0.1169 0.3195
## [367,] 0.1863 0.1168 0.3196
## [368,] 0.1862 0.1168 0.3194
## [369,] 0.1863 0.1168 0.3196
## [370,] 0.1863 0.1169 0.3194
## [371,] 0.1864 0.1170 0.3196
## [372,] 0.1863 0.1169 0.3195
## [373,] 0.1862 0.1167 0.3196
## [374,] 0.1863 0.1167 0.3196
## [375,] 0.1862 0.1167 0.3196
## [376,] 0.1862 0.1167 0.3195
## [377,] 0.1864 0.1169 0.3196
## [378,] 0.1864 0.1169 0.3196
## [379,] 0.1862 0.1166 0.3197
## [380,] 0.1862 0.1167 0.3194
## [381,] 0.1862 0.1167 0.3196
## [382,] 0.1863 0.1168 0.3195
## [383,] 0.1862 0.1167 0.3195
## [384,] 0.1862 0.1167 0.3196
## [385,] 0.1861 0.1166 0.3194
## [386,] 0.1860 0.1165 0.3194
## [387,] 0.1862 0.1166 0.3195
## [388,] 0.1862 0.1166 0.3197
## [389,] 0.1861 0.1165 0.3196
## [390,] 0.1860 0.1165 0.3194
## [391,] 0.1861 0.1165 0.3196
## [392,] 0.1861 0.1166 0.3193
## [393,] 0.1861 0.1166 0.3194
## [394,] 0.1862 0.1166 0.3196
## [395,] 0.1861 0.1166 0.3195
## [396,] 0.1861 0.1166 0.3195
## [397,] 0.1861 0.1165 0.3195
## [398,] 0.1860 0.1165 0.3195
## [399,] 0.1861 0.1165 0.3196
## [400,] 0.1860 0.1164 0.3196
## [401,] 0.1861 0.1165 0.3196
## [402,] 0.1860 0.1164 0.3195
## [403,] 0.1860 0.1165 0.3194
## [404,] 0.1860 0.1165 0.3195
## [405,] 0.1860 0.1164 0.3195
## [406,] 0.1860 0.1164 0.3196
## [407,] 0.1859 0.1163 0.3195
## [408,] 0.1860 0.1164 0.3195
## [409,] 0.1861 0.1164 0.3197
## [410,] 0.1860 0.1163 0.3195
## [411,] 0.1860 0.1164 0.3196
## [412,] 0.1860 0.1164 0.3196
## [413,] 0.1860 0.1164 0.3196
## [414,] 0.1860 0.1165 0.3195
## [415,] 0.1860 0.1164 0.3195
## [416,] 0.1862 0.1166 0.3197
## [417,] 0.1860 0.1164 0.3194
## [418,] 0.1859 0.1163 0.3194
## [419,] 0.1860 0.1164 0.3196
## [420,] 0.1861 0.1166 0.3194
## [421,] 0.1860 0.1164 0.3195
## [422,] 0.1861 0.1166 0.3195
## [423,] 0.1860 0.1164 0.3194
## [424,] 0.1860 0.1165 0.3193
## [425,] 0.1860 0.1163 0.3196
## [426,] 0.1859 0.1163 0.3194
## [427,] 0.1859 0.1163 0.3195
## [428,] 0.1860 0.1163 0.3196
## [429,] 0.1860 0.1164 0.3194
## [430,] 0.1860 0.1164 0.3196
## [431,] 0.1860 0.1164 0.3196
## [432,] 0.1860 0.1164 0.3196
## [433,] 0.1860 0.1164 0.3195
## [434,] 0.1861 0.1165 0.3197
## [435,] 0.1861 0.1165 0.3196
## [436,] 0.1860 0.1164 0.3194
## [437,] 0.1860 0.1165 0.3195
## [438,] 0.1861 0.1165 0.3195
## [439,] 0.1860 0.1163 0.3197
## [440,] 0.1860 0.1164 0.3197
## [441,] 0.1860 0.1164 0.3195
## [442,] 0.1860 0.1163 0.3195
## [443,] 0.1860 0.1164 0.3196
## [444,] 0.1860 0.1164 0.3195
## [445,] 0.1860 0.1164 0.3195
## [446,] 0.1860 0.1164 0.3194
## [447,] 0.1860 0.1163 0.3197
## [448,] 0.1861 0.1164 0.3196
## [449,] 0.1861 0.1164 0.3197
## [450,] 0.1859 0.1163 0.3194
## [451,] 0.1860 0.1165 0.3194
## [452,] 0.1860 0.1165 0.3194
## [453,] 0.1859 0.1165 0.3192
## [454,] 0.1860 0.1165 0.3192
## [455,] 0.1859 0.1164 0.3192
## [456,] 0.1859 0.1165 0.3192
## [457,] 0.1860 0.1165 0.3193
## [458,] 0.1861 0.1165 0.3195
## [459,] 0.1861 0.1165 0.3195
## [460,] 0.1860 0.1165 0.3193
## [461,] 0.1859 0.1165 0.3191
## [462,] 0.1860 0.1166 0.3192
## [463,] 0.1859 0.1165 0.3192
## [464,] 0.1859 0.1164 0.3193
## [465,] 0.1859 0.1164 0.3192
## [466,] 0.1859 0.1163 0.3194
## [467,] 0.1860 0.1164 0.3194
## [468,] 0.1860 0.1165 0.3192
## [469,] 0.1860 0.1165 0.3194
## [470,] 0.1861 0.1165 0.3196
## [471,] 0.1860 0.1164 0.3195
## [472,] 0.1860 0.1164 0.3194
## [473,] 0.1861 0.1165 0.3196
## [474,] 0.1861 0.1164 0.3198
## [475,] 0.1861 0.1165 0.3197
## [476,] 0.1860 0.1164 0.3195
## [477,] 0.1859 0.1163 0.3195
## [478,] 0.1859 0.1163 0.3193
## [479,] 0.1859 0.1164 0.3193
## [480,] 0.1859 0.1163 0.3193
## [481,] 0.1859 0.1164 0.3191
## [482,] 0.1859 0.1164 0.3193
## [483,] 0.1858 0.1163 0.3192
## [484,] 0.1859 0.1163 0.3194
## [485,] 0.1859 0.1163 0.3194
## [486,] 0.1859 0.1163 0.3194
## [487,] 0.1858 0.1162 0.3194
## [488,] 0.1858 0.1163 0.3192
## [489,] 0.1858 0.1163 0.3192
## [490,] 0.1857 0.1162 0.3190
## [491,] 0.1859 0.1163 0.3193
## [492,] 0.1859 0.1163 0.3194
## [493,] 0.1858 0.1163 0.3191
## [494,] 0.1857 0.1163 0.3190
## [495,] 0.1857 0.1162 0.3191
## [496,] 0.1858 0.1162 0.3193
## [497,] 0.1858 0.1162 0.3192
## [498,] 0.1858 0.1162 0.3193
## [499,] 0.1858 0.1163 0.3193
## [500,] 0.1858 0.1163 0.3193
```

Looks like there's been a little improvement, make a prediction

```r
# pred <- predict(rf2, test, type='prob')
```


```r
# ## add EventId to pred pred.df <- data.frame(EventId=test$EventId,
# b=pred[,'b'], s=pred[,'s']) # order pred.df by increasing s to get the
# RankOrder require(plyr) ordered.pred <- arrange(pred.df, s) Class <-
# apply(ordered.pred, 1, function(p) ifelse(p['s'] > p['b'], 's', 'b'))
# final.prediction <-
# data.frame(EventId=ordered.pred$EventId,RankOrder=1:550000,Class)
# write.csv(final.prediction, file='submission3.csv', row.names=F, quote=F)
```




